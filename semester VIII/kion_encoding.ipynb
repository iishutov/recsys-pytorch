{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter = pd.read_csv('./mod_data/interactions.csv')\n",
    "df_items = pd.read_csv('./mod_data/items.csv')\n",
    "df_users = pd.read_csv('./mod_data/users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>age_rating</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>7434</td>\n",
       "      <td>series</td>\n",
       "      <td>Далеко от тебя</td>\n",
       "      <td>мелодрамы, комедии</td>\n",
       "      <td>18</td>\n",
       "      <td>Далеко, от, тебя, 2019, Россия</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id content_type           title              genres  age_rating  \\\n",
       "4229     7434       series  Далеко от тебя  мелодрамы, комедии          18   \n",
       "\n",
       "                            keywords  \n",
       "4229  Далеко, от, тебя, 2019, Россия  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords extraction\n",
    "def tokenize(line):\n",
    "    vec = [word for word in line.split(', ') if not word.isnumeric() and word not in {'', 'nan'}]\n",
    "    return vec\n",
    "\n",
    "keywords_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize, token_pattern=None,\n",
    "    max_features=100, stop_words=list(STOP_WORDS)\n",
    ")\n",
    "X_keywords = keywords_vectorizer.fit_transform(df_items['keywords'].values.astype('U'))\n",
    "\n",
    "# content type preprocessing\n",
    "X_content_type = (df_items['content_type'] == 'film').astype(int).values.reshape(-1, 1)\n",
    "\n",
    "# age rating preprocessing\n",
    "age_rating_encoder = OneHotEncoder()\n",
    "X_age_rating = age_rating_encoder.fit_transform(df_items['age_rating'].values.astype('U').reshape(-1, 1)).toarray()\n",
    "\n",
    "# genres preprocessing\n",
    "genres_vectorizer = TfidfVectorizer(tokenizer=tokenize, token_pattern=None)\n",
    "X_genres = genres_vectorizer.fit_transform(df_items['genres'].values.astype('U')).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "россия                     2646.475781\n",
       "соединенные штаты          1650.497265\n",
       "отношения                  1344.449214\n",
       "франция                    1185.161904\n",
       "сша                        1085.736725\n",
       "ссср                        756.435969\n",
       "любовь                      633.931426\n",
       "дружба                      599.568120\n",
       "соединенное королевство     495.680623\n",
       "женщины                     490.716083\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=np.squeeze(np.asarray(X_keywords.sum(axis=0))), index=keywords_vectorizer.get_feature_names_out())\\\n",
    "    .sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15963, 202)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_items = np.hstack([\n",
    "    X_content_type,\n",
    "    X_genres,\n",
    "    X_age_rating,\n",
    "    X_keywords.todense()\n",
    "])\n",
    "X_items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171442</th>\n",
       "      <td>1066107</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id        age        income sex  kids_flg\n",
       "171442  1066107  age_35_44  income_40_60   Ж         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age extraction\n",
    "age_encoder = OneHotEncoder()\n",
    "X_age = age_encoder.fit_transform(df_users['age'].values.astype('U').reshape(-1, 1)).toarray()\n",
    "\n",
    "# income extraction\n",
    "income_encoder = OneHotEncoder()\n",
    "X_income = income_encoder.fit_transform(df_users['income'].values.astype('U').reshape(-1, 1)).toarray()\n",
    "\n",
    "# sex extraction\n",
    "X_sex = (df_users['sex'] == 'М').astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840197, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_users = np.hstack([\n",
    "    X_age,\n",
    "    X_income,\n",
    "    X_sex,\n",
    "    df_users['kids_flg'].to_numpy().reshape(-1, 1)\n",
    "])\n",
    "X_users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-2.1.0+cu121.html\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
    "from torch_geometric.metrics import (\n",
    "    LinkPredMAP,\n",
    "    LinkPredPrecision,\n",
    "    LinkPredRecall,\n",
    ")\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION']='1'\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_idx = {user_id: idx for idx, user_id in df_users['user_id'].items()}\n",
    "item_id_to_idx = {item_id: idx for idx, item_id in df_items['item_id'].items()}\n",
    "\n",
    "edges = np.vstack([\n",
    "    df_inter['user_id'].map(user_id_to_idx).values,\n",
    "    df_inter['item_id'].map(item_id_to_idx).values\n",
    "])\n",
    "\n",
    "connections = np.ones(edges.shape[1])\n",
    "time = pd.to_datetime(df_inter['last_watch_dt'], format='%Y-%m-%d').values.astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  movie={ x=[15963, 202] },\n",
       "  user={ x=[840197, 14] },\n",
       "  (user, watched, movie)={\n",
       "    edge_index=[2, 1288996],\n",
       "    time=[1288996],\n",
       "  },\n",
       "  (movie, rev_watched, user)={\n",
       "    edge_index=[2, 1288996],\n",
       "    time=[1288996],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Add item node features\n",
    "data['movie'].x = torch.Tensor(X_items)\n",
    "# Add user node features for message passing\n",
    "data['user'].x = torch.Tensor(X_users)\n",
    "\n",
    "# Add edges (users connections with movies)\n",
    "data['user', 'watched', 'movie'].edge_index = torch.tensor(edges)\n",
    "data['user', 'watched', 'movie'].time = torch.tensor(time)\n",
    "\n",
    "# Add a reverse relation for message passing\n",
    "data = T.ToUndirected()(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4029/4029 [01:35<00:00, 42.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.2546\n",
      "Test MAP@10: 0.0604, Test Precision@10: 0.0270, Test Recall@10: 0.1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1111/4029 [00:26<01:10, 41.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 173\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28mfloat\u001b[39m(map_metric\u001b[38;5;241m.\u001b[39mcompute()),\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mfloat\u001b[39m(precision_metric\u001b[38;5;241m.\u001b[39mcompute()),\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28mfloat\u001b[39m(recall_metric\u001b[38;5;241m.\u001b[39mcompute()),\n\u001b[0;32m    169\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    175\u001b[0m     val_map, val_precision, val_recall \u001b[38;5;241m=\u001b[39m test(\n\u001b[0;32m    176\u001b[0m         test_edge_label_index,\n\u001b[0;32m    177\u001b[0m         test_exclude_links,\n\u001b[0;32m    178\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[13], line 106\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    104\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(out, y)\n\u001b[0;32m    105\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 106\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(loss) \u001b[38;5;241m*\u001b[39m y\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m    109\u001b[0m total_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:490\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Handle complex parameters\u001b[39;00m\n\u001b[0;32m    489\u001b[0m device_grads \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_grads]\n\u001b[1;32m--> 490\u001b[0m device_exp_avgs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview_as_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice_exp_avgs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    491\u001b[0m device_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avg_sqs]\n\u001b[0;32m    492\u001b[0m device_max_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_max_exp_avg_sqs]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\optim\\adam.py:490\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# Handle complex parameters\u001b[39;00m\n\u001b[0;32m    489\u001b[0m device_grads \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_grads]\n\u001b[1;32m--> 490\u001b[0m device_exp_avgs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avgs]\n\u001b[0;32m    491\u001b[0m device_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_exp_avg_sqs]\n\u001b[0;32m    492\u001b[0m device_max_exp_avg_sqs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mview_as_real(x) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(x) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m device_max_exp_avg_sqs]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of predictions\n",
    "k = 10\n",
    "\n",
    "# Perform a temporal link-level split into training and test edges:\n",
    "edge_label_index = data['user', 'movie'].edge_index\n",
    "time = data['user', 'movie'].time\n",
    "\n",
    "perm = time.argsort()\n",
    "train_index = perm[:int(0.8 * perm.numel())]\n",
    "test_index = perm[int(0.8 * perm.numel()):]\n",
    "\n",
    "kwargs = dict(  # Shared data loader arguments:\n",
    "    data=data,\n",
    "    num_neighbors=[10, 10],\n",
    "    batch_size=256,\n",
    "    time_attr='time',\n",
    "    num_workers=0,\n",
    "    persistent_workers=False,\n",
    "    temporal_strategy='last',\n",
    ")\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    edge_label_index=(('user', 'movie'), edge_label_index[:, train_index]),\n",
    "    edge_label_time=time[train_index] - 1,  # No leakage.\n",
    "    neg_sampling=dict(mode='binary', amount=2),\n",
    "    shuffle=True,\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "# During testing, we sample node-level subgraphs from both endpoints to\n",
    "# retrieve their embeddings.\n",
    "# This allows us to do efficient k-NN search on top of embeddings:\n",
    "src_loader = NeighborLoader(\n",
    "    input_nodes='user',\n",
    "    input_time=(time[test_index].min() - 1).repeat(data['user'].num_nodes),\n",
    "    **kwargs,\n",
    ")\n",
    "dst_loader = NeighborLoader(\n",
    "    input_nodes='movie',\n",
    "    input_time=(time[test_index].min() - 1).repeat(data['movie'].num_nodes),\n",
    "    **kwargs,\n",
    ")\n",
    "\n",
    "# Save test edges and the edges we want to exclude when evaluating:\n",
    "sparse_size = (data['user'].num_nodes, data['movie'].num_nodes)\n",
    "test_edge_label_index = EdgeIndex(\n",
    "    edge_label_index[:, test_index].to(device),\n",
    "    sparse_size=sparse_size,\n",
    ").sort_by('row')[0]\n",
    "test_exclude_links = EdgeIndex(\n",
    "    edge_label_index[:, train_index].to(device),\n",
    "    sparse_size=sparse_size,\n",
    ").sort_by('row')[0]\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = gnn.SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = gnn.SAGEConv((-1, -1), hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    def forward(self, x_dict, edge_label_index):\n",
    "        x_src = x_dict['user'][edge_label_index[0]]\n",
    "        x_dst = x_dict['movie'][edge_label_index[1]]\n",
    "        return (x_src * x_dst).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNN(hidden_channels)\n",
    "        self.encoder = gnn.to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = InnerProductDecoder()\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        x_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(x_dict, edge_label_index)\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(\n",
    "            batch.x_dict,\n",
    "            batch.edge_index_dict,\n",
    "            batch['user', 'movie'].edge_label_index,\n",
    "        )\n",
    "        y = batch['user', 'movie'].edge_label\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * y.numel()\n",
    "        total_examples += y.numel()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(edge_label_index, exclude_links):\n",
    "    model.eval()\n",
    "\n",
    "    dst_embs = []\n",
    "    for batch in dst_loader:  # Collect destination node/movie embeddings:\n",
    "        batch = batch.to(device)\n",
    "        emb = model.encoder(batch.x_dict, batch.edge_index_dict)['movie'].cpu()\n",
    "        emb = emb[:batch['movie'].batch_size]\n",
    "        dst_embs.append(emb)\n",
    "    dst_emb = torch.cat(dst_embs, dim=0)\n",
    "    del dst_embs\n",
    "\n",
    "    # Instantiate k-NN index based on maximum inner product search (MIPS):\n",
    "    mips = gnn.MIPSKNNIndex(dst_emb)\n",
    "\n",
    "    # Initialize metrics:\n",
    "    map_metric = LinkPredMAP(k=k)\n",
    "    precision_metric = LinkPredPrecision(k=k)\n",
    "    recall_metric = LinkPredRecall(k=k)\n",
    "\n",
    "    num_processed = 0\n",
    "    for batch in src_loader:  # Collect source node/user embeddings:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Compute user embeddings:\n",
    "        emb = model.encoder(batch.x_dict, batch.edge_index_dict)['user']\n",
    "        emb = emb[:batch['user'].batch_size]\n",
    "\n",
    "        # Filter labels/exclusion by current batch:\n",
    "        _edge_label_index = edge_label_index.sparse_narrow(\n",
    "            dim=0,\n",
    "            start=num_processed,\n",
    "            length=emb.size(0),\n",
    "        ).cpu()\n",
    "        _exclude_links = exclude_links.sparse_narrow(\n",
    "            dim=0,\n",
    "            start=num_processed,\n",
    "            length=emb.size(0),\n",
    "        ).cpu()\n",
    "        num_processed += emb.size(0)\n",
    "\n",
    "\n",
    "        # Perform MIPS search:\n",
    "        _, pred_index_mat = mips.search(emb.cpu(), k, _exclude_links)\n",
    "\n",
    "        # Update retrieval metrics:\n",
    "        map_metric.update(pred_index_mat, _edge_label_index)\n",
    "        precision_metric.update(pred_index_mat, _edge_label_index)\n",
    "        recall_metric.update(pred_index_mat, _edge_label_index)\n",
    "\n",
    "    return (\n",
    "        float(map_metric.compute()),\n",
    "        float(precision_metric.compute()),\n",
    "        float(recall_metric.compute()),\n",
    "    )\n",
    "\n",
    "\n",
    "for epoch in range(1, 16):\n",
    "    train_loss = train()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {train_loss:.4f}')\n",
    "    val_map, val_precision, val_recall = test(\n",
    "        test_edge_label_index,\n",
    "        test_exclude_links,\n",
    "    )\n",
    "    print(f'Test MAP@{k}: {val_map:.4f}, '\n",
    "          f'Test Precision@{k}: {val_precision:.4f}, '\n",
    "          f'Test Recall@{k}: {val_recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
